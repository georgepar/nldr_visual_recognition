{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Learning for Speech Emotion Recognition\n",
    "## Efthymios Tzinis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the appropriate modules \n",
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "sys.path.append('../')\n",
    "import config\n",
    "sys.path.append(config.BASE_PATH)\n",
    "from dataloader import fused_features_IEMOCAP as IEMOCAP_loader\n",
    "\n",
    "sys.path.append(config.PATTERN_SEARCH_MDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Folds Generator\n",
    "def get_dataset_in_one_array(features_dic,\n",
    "                             included_sessions=['Ses01', 'Ses02']):\n",
    "    speaker_indices = {}\n",
    "    x_all_list = []\n",
    "    Y_all = []\n",
    "    prev_ind = 0\n",
    "    for te_speaker, te_data in features_dic.items():  \n",
    "        ses_name = te_speaker[:-1]\n",
    "        if not ses_name in included_sessions:\n",
    "            continue\n",
    "        x_all_list.append(te_data['x'])\n",
    "        Y_all += te_data['y']\n",
    "        this_speaker_samples = len(te_data['y'])\n",
    "        \n",
    "        speaker_indices[te_speaker] = (prev_ind, prev_ind + this_speaker_samples)\n",
    "        prev_ind += this_speaker_samples\n",
    "        X_all = np.concatenate(x_all_list, axis=0)\n",
    "    return X_all, Y_all, speaker_indices, len(included_sessions)\n",
    "\n",
    "\n",
    "def generate_session_folds(X_all, Y_all, features_dic, speaker_indices):\n",
    "    sorted_speakers = sorted(speaker_indices)\n",
    "    for i in np.arange(0, len(sorted_speakers), 2):\n",
    "        sp1 = sorted_speakers[i]\n",
    "        sp2 = sorted_speakers[i+1]\n",
    "        \n",
    "        session_name = sp1[:-1]\n",
    "        \n",
    "        st1, et1 = speaker_indices[sp1]\n",
    "        st2, et2 = speaker_indices[sp2]\n",
    "        \n",
    "        Y_te = features_dic[sp1]['y'] + features_dic[sp2]['y']\n",
    "        X_te = np.concatenate([X_all[st1:et1, :], X_all[st2:et2, :]], axis=0)\n",
    "        \n",
    "        x_tr_list = []\n",
    "        Y_tr = []\n",
    "        for sp in sorted_speakers:\n",
    "            if sp == sp1 or sp == sp2:\n",
    "                continue\n",
    "            st, et = speaker_indices[sp] \n",
    "            x_tr_list.append(X_all[st:et, :])\n",
    "            Y_tr += features_dic[sp]['y']\n",
    "            \n",
    "        X_tr = np.concatenate(x_tr_list, axis=0)    \n",
    "        \n",
    "        yield session_name, X_te, Y_te, X_tr, Y_tr \n",
    "\n",
    "def generate_folds(features_dic,\n",
    "                   group_by = 'speaker'):\n",
    "    if group_by == 'speaker':\n",
    "        for te_speaker, te_data in features_dic.items():\n",
    "            x_tr_list = []\n",
    "            Y_tr = []\n",
    "            for tr_speaker, tr_data in features_dic.items():\n",
    "                if tr_speaker == te_speaker:\n",
    "                    continue\n",
    "                x_tr_list.append(tr_data['x'])\n",
    "                Y_tr += tr_data['y']\n",
    "\n",
    "            X_tr = np.concatenate(x_tr_list, axis=0)\n",
    "            yield te_speaker, te_data['x'], te_data['y'], X_tr, Y_tr\n",
    "     \n",
    "    elif group_by == 'session':\n",
    "        already_tested = []\n",
    "        for te_speaker, te_data in features_dic.items():\n",
    "            if not (te_speaker[:-1] in already_tested) :\n",
    "                already_tested.append(te_speaker[:-1])\n",
    "            else:\n",
    "                continue\n",
    "            X_val =  te_data['x']\n",
    "            Y_val = te_data['y']\n",
    "            x_tr_list = []\n",
    "            Y_tr = []\n",
    "            ses_name = te_speaker[:-1]\n",
    "            for tr_speaker, tr_data in features_dic.items():\n",
    "                if tr_speaker == te_speaker:\n",
    "                    continue\n",
    "                if tr_speaker[:-1] == ses_name:\n",
    "                    val_speaker = tr_speaker\n",
    "                    X_val = tr_data['x']\n",
    "                    Y_val = tr_data['y']\n",
    "                    continue\n",
    "                x_tr_list.append(tr_data['x'])\n",
    "                Y_tr += tr_data['y']\n",
    "\n",
    "            X_tr = np.concatenate(x_tr_list, axis=0)\n",
    "            X_ses = np.concatenate([te_data['x'], X_val], axis=0)\n",
    "            Y_ses = te_data['y'] + Y_val\n",
    "            yield ses_name, X_ses, Y_ses, X_tr, Y_tr\n",
    "            \n",
    "def fuse_excited_happiness(l):\n",
    "    return ['happy + excited' \n",
    "            if (e == 'excited' or e == 'happy') \n",
    "            else e for e in l ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "class IEMOCAPData(Dataset):\n",
    "    def __init__(self, X,):\n",
    "        self.X_high = X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X_high.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_high[idx]\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, hidden_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, in_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        x = self.decoder(h)\n",
    "        return x, h\n",
    "\n",
    "\n",
    "class AE(object):\n",
    "    def __init__(self, original_dim, target_dim, batch_size=32, learning_rate=1e-4, num_epochs=10000, early_stop=10):\n",
    "        self.original_dim = original_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.early_stop = early_stop\n",
    "        self.dvc = 'cuda'\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        iemo_data = IEMOCAPData(X)\n",
    "\n",
    "        dataloader = DataLoader(iemo_data, batch_size=self.batch_size, shuffle=True)\n",
    "        model = autoencoder(self.original_dim, self.target_dim).to(self.dvc)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        patience = 0\n",
    "        prev_avg_loss = np.Inf\n",
    "        for epoch in range(self.num_epochs):\n",
    "            avg_loss, i = 0, 0\n",
    "            for data in dataloader:\n",
    "                data = torch.Tensor(data.type(torch.FloatTensor)).to(self.dvc)\n",
    "                # ===================forward=====================\n",
    "                output, hidden = model(data)\n",
    "        #         loss = criterion(output, data, hidden)\n",
    "                loss = criterion(output, data)\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss\n",
    "                i += 1\n",
    "            # ===================log========================\n",
    "            if avg_loss.data[0] > prev_avg_loss:\n",
    "                patience += 1\n",
    "            print('epoch [{}/{}], loss:{}, patience: {}'\n",
    "                  .format(epoch + 1, self.num_epochs, avg_loss.data[0] / i, patience))\n",
    "            if patience >= self.early_stop:\n",
    "                break\n",
    "            prev_avg_loss = avg_loss.data[0]\n",
    "        self.model = model\n",
    "        return model\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.model = self.fit(X)\n",
    "        return self.transorm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all avaiulable Manifold Methods\n",
    "import multidimensional\n",
    "import multidimensional.common\n",
    "import multidimensional.mds \n",
    "import multidimensional.smacof\n",
    "import multidimensional.mds_utils as mds_utils\n",
    "from sklearn import manifold, decomposition\n",
    "\n",
    "class IdentityData(object):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        return x\n",
    "\n",
    "def get_manifold_methods(original_dim, target_dim):\n",
    "    method_n_comp = 66\n",
    "    radius_barrier = 1e-3\n",
    "    explore_dim_percent = 1\n",
    "    starting_radius =32\n",
    "    max_turns = 100\n",
    "    point_filter = (multidimensional.point_filters.FixedStochasticFilter(keep_percent=1, recalculate_each=10))\n",
    "    radius_update = (multidimensional.radius_updates.AdaRadiusHalving(tolerance=.5*1e-3, burnout_tolerance=100000))\n",
    "\n",
    "    mds_obj = multidimensional.mds.MDS(target_dim, point_filter, radius_update, starting_radius=starting_radius, \n",
    "                                       radius_barrier=radius_barrier,\n",
    "                max_turns=max_turns, keep_history=False,\n",
    "                explore_dim_percent=explore_dim_percent)\n",
    "\n",
    "    manifold_methods = {\n",
    "        'Pattern Search MDS': { 'results': {}, 'object': multidimensional.mds.MDS(target_dim, point_filter, \n",
    "                                                         radius_update, starting_radius=starting_radius, \n",
    "                                                         radius_barrier=radius_barrier, max_turns=max_turns, \n",
    "                                                         keep_history=False,\n",
    "                                                         dissimilarities='precomputed',\n",
    "                                                         explore_dim_percent=explore_dim_percent)},\n",
    "        'MDS SMACOF': { 'results': {}, 'object': multidimensional.smacof.MDS(n_components=target_dim, n_init=1, \n",
    "                                                 max_iter=max_turns, dissimilarity='euclidean', n_jobs=8)},\n",
    "        'LTSA': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='ltsa',n_jobs=8)},\n",
    "        'Modified LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='modified',n_jobs=8)},\n",
    "        'Hessian LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='hessian',n_jobs=8)},\n",
    "        'LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='standard',n_jobs=8)},\n",
    "        'Truncated SVD': { 'results': {}, 'object': decomposition.TruncatedSVD(n_components=target_dim)},\n",
    "        'Spectral Embedding': { 'results': {}, 'object': manifold.SpectralEmbedding(n_components=target_dim, \n",
    "                                                                                    n_jobs=8)},\n",
    "        'TSNE': { 'results': {}, 'object': manifold.TSNE(n_components=target_dim)},\n",
    "        'ISOMAP': { 'results': {}, 'object': manifold.Isomap(12, target_dim)},\n",
    "        'Original Data': { 'results': {}, 'object': IdentityData()},\n",
    "        'Autoencoder': { 'results': {}, 'object': AE(original_dim, target_dim) }\n",
    "\n",
    "    }\n",
    "    return manifold_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto=None):\n",
    "    save_file = os.path.join('../', 'cache', saveto)\n",
    "    if saveto is not None os.path.isfile(save_file):\n",
    "        with open(save_file, 'rb') as fd:\n",
    "            reduced = pickle.load(fd)\n",
    "        return reduced\n",
    "    X_all, Y_all, speaker_indices, number_of_sessions = get_dataset_in_one_array(data_dic,\n",
    "                                                                                included_sessions=included_sessions)\n",
    "    # normalize the input vectors \n",
    "    X_high = StandardScaler().fit_transform(X_all)\n",
    "    \n",
    "    print(X_high.shape)\n",
    "    \n",
    "    reduced = {}\n",
    "    original_dim = X_all.shape[1]\n",
    "    for target_dim in target_dims:\n",
    "        reduced[target_dim] = {}\n",
    "        manifold_methods = get_manifold_methods(original_dim, target_dim)\n",
    "    #     methods_to_test = manifold_methods.keys()\n",
    "        methods_metrics = {}\n",
    "        for selected_method in methods_to_test:            \n",
    "            print('Checking Method: {}'.format(selected_method))\n",
    "            \n",
    "            print('Reducing Input from Dimension: {} to a Lower Embedded Manifold with dimensions: {}...'.format(\n",
    "                   X_high.shape[1], target_dim))\n",
    "            try:\n",
    "                obj = manifold_methods[selected_method]['object']\n",
    "                if selected_method == 'Pattern Search MDS':\n",
    "                    d_goal = multidimensional.common.DISTANCE_MATRIX(X_high.astype(np.float64))\n",
    "    #                 d_goal = 1.0 - np.corrcoef(X_high.astype(np.float64))\n",
    "    #                 np.fill_diagonal(d_goal, 0)\n",
    "                    X_low = obj.fit_transform(d_goal)\n",
    "                else:\n",
    "                    X_low = obj.fit_transform(X_high)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                X_low = None\n",
    "            reduced[target_dim][selected_method] = X_low\n",
    "    if saveto is not None:\n",
    "        with open(save_file, 'wb') as fd:\n",
    "            pickle.dump(reduced, fd)\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the best performing nonlinear features for KNN classification after dimensionality reduction\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pprint \n",
    "import pandas as pd \n",
    "\n",
    "def run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions):\n",
    "    _, Y_all, speaker_indices, number_of_sessions = get_dataset_in_one_array(\n",
    "        data_dic, included_sessions=included_sessions)\n",
    "    df_results = {}\n",
    "    for target_dim, methods in reduced.iteritems():\n",
    "        methods_metrics = {}\n",
    "        for selected_method, X_low in methods.iteritems():\n",
    "            print('Checking Method: {}'.format(selected_method))\n",
    "            metrics_l = {'uw_acc': dict([(k, 0.0) for k in n_neighbors]), 'w_acc': dict([(k, 0.0) for k in n_neighbors])}\n",
    "            if X_low is None:\n",
    "                methods_metrics[selected_method+' UA'] = metrics_l['uw_acc']\n",
    "                methods_metrics[selected_method+' WA'] = metrics_l['w_acc']\n",
    "                continue\n",
    "                \n",
    "            for k in n_neighbors:\n",
    "    #             print 'Testing for Nearest Neighbors: K={}'.format(k)\n",
    "                knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='brute', leaf_size=30, \n",
    "                                           p=2, metric='minkowski', metric_params=None, n_jobs=8)\n",
    "\n",
    "                session_folds = generate_session_folds(X_low, Y_all, data_dic, speaker_indices)\n",
    "                for session, X_te, Y_te, X_tr, Y_tr in session_folds:\n",
    "    #                 print \"Testing for Session: {}\".format(session)\n",
    "                    Y_te, Y_tr = fuse_excited_happiness(Y_te), fuse_excited_happiness(Y_tr)\n",
    "                    \n",
    "                    try:\n",
    "                        knn.fit(X_tr, Y_tr) \n",
    "                        Y_predicted = knn.predict(X_te)\n",
    "\n",
    "                        w_acc = accuracy_score(Y_predicted, Y_te)\n",
    "                        cmat = confusion_matrix(Y_te, Y_predicted)\n",
    "                        with np.errstate(divide='ignore'):\n",
    "                            uw_acc = (cmat.diagonal() / (1.0 * cmat.sum(axis=1) + 1e-6)).mean()\n",
    "                            if np.isnan(uw_acc):\n",
    "                                uw_acc = 0.\n",
    "                        w_acc = round(w_acc*100,1)\n",
    "                        uw_acc = round(uw_acc*100,1)\n",
    "                        metrics_l['uw_acc'][k] += uw_acc/number_of_sessions\n",
    "                        metrics_l['w_acc'][k] += w_acc/number_of_sessions\n",
    "                    except:\n",
    "                        metrics_l['uw_acc'][k] += 0.\n",
    "                        metrics_l['w_acc'][k] += 0.\n",
    "    #             print 'Done'\n",
    "            methods_metrics[selected_method+' UA'] = metrics_l['uw_acc']\n",
    "            methods_metrics[selected_method+' WA'] = metrics_l['w_acc']\n",
    "#             pprint.pprint(metrics_l)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(methods_metrics, orient=\"index\")\n",
    "        df_results[target_dim] = df[sorted(df.columns)]\n",
    "        \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameters for IEMOCAP Session Experiments \n",
    "n_neighbors = np.arange(1, 40, 4)\n",
    "\n",
    "# Find all appropriate files \n",
    "IEMOCAP_data_path = '/home/george/all_TRUE_IEMOCAP_feats/'\n",
    "l_feats_p = IEMOCAP_data_path + 'linear/IEMOCAP_linear_emobase2010'\n",
    "# nl_feats_l = glob.glob( IEMOCAP_data_path + '/utterance/*.dat')\n",
    "# nl_feats_p = nl_feats_l.pop()\n",
    "nl_feats_p = os.path.join(IEMOCAP_data_path, \n",
    "             'utterance/IEMOCAP-rqa-ad_hoc-tau-7-supremum-recurrence_rate-0.15-dur-0.03-fs-16000.dat')\n",
    "included_sessions=['Ses01', 'Ses02', 'Ses03', 'Ses04', 'Ses05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531, 2014)\n",
      "Checking Method: Autoencoder\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:78: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:81: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:84: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10000], loss:0.642158389091, patience: 0\n",
      "epoch [2/10000], loss:0.502191781998, patience: 0\n",
      "epoch [3/10000], loss:0.459500998259, patience: 0\n",
      "epoch [4/10000], loss:0.43812212348, patience: 0\n",
      "epoch [5/10000], loss:0.419775217772, patience: 0\n",
      "epoch [6/10000], loss:0.406265258789, patience: 0\n",
      "epoch [7/10000], loss:0.396254956722, patience: 0\n",
      "epoch [8/10000], loss:0.388491630554, patience: 0\n",
      "epoch [9/10000], loss:0.380748003721, patience: 0\n",
      "epoch [10/10000], loss:0.372565329075, patience: 0\n",
      "epoch [11/10000], loss:0.368515461683, patience: 0\n",
      "epoch [12/10000], loss:0.365899145603, patience: 0\n",
      "epoch [13/10000], loss:0.362794071436, patience: 0\n",
      "epoch [14/10000], loss:0.356867492199, patience: 0\n",
      "epoch [15/10000], loss:0.354566812515, patience: 0\n",
      "epoch [16/10000], loss:0.347530305386, patience: 0\n",
      "epoch [17/10000], loss:0.341391742229, patience: 0\n",
      "epoch [18/10000], loss:0.34833586216, patience: 1\n",
      "epoch [19/10000], loss:0.34206071496, patience: 1\n",
      "epoch [20/10000], loss:0.337718635798, patience: 1\n",
      "epoch [21/10000], loss:0.334161490202, patience: 1\n",
      "epoch [22/10000], loss:0.331348210573, patience: 1\n",
      "epoch [23/10000], loss:0.329716831446, patience: 1\n",
      "epoch [24/10000], loss:0.327369660139, patience: 1\n",
      "epoch [25/10000], loss:0.326517015696, patience: 1\n",
      "epoch [26/10000], loss:0.338203430176, patience: 2\n",
      "epoch [27/10000], loss:0.328744620085, patience: 2\n",
      "epoch [28/10000], loss:0.325439423323, patience: 2\n",
      "epoch [29/10000], loss:0.323994100094, patience: 2\n",
      "epoch [30/10000], loss:0.322723060846, patience: 2\n",
      "epoch [31/10000], loss:0.320455223322, patience: 2\n",
      "epoch [32/10000], loss:0.31817600131, patience: 2\n",
      "epoch [33/10000], loss:0.317223966122, patience: 2\n",
      "epoch [34/10000], loss:0.316665142775, patience: 2\n",
      "epoch [35/10000], loss:0.3164960742, patience: 2\n",
      "epoch [36/10000], loss:0.314788073301, patience: 2\n",
      "epoch [37/10000], loss:0.312852591276, patience: 2\n",
      "epoch [38/10000], loss:0.312117129564, patience: 2\n",
      "epoch [39/10000], loss:0.313242852688, patience: 3\n",
      "epoch [40/10000], loss:0.313230365515, patience: 3\n",
      "epoch [41/10000], loss:0.309829592705, patience: 3\n",
      "epoch [42/10000], loss:0.306906312704, patience: 3\n",
      "epoch [43/10000], loss:0.307155460119, patience: 4\n",
      "epoch [44/10000], loss:0.308146774769, patience: 5\n",
      "epoch [45/10000], loss:0.306291282177, patience: 5\n",
      "epoch [46/10000], loss:0.304944932461, patience: 5\n",
      "epoch [47/10000], loss:0.304828196764, patience: 5\n",
      "epoch [48/10000], loss:0.308674961329, patience: 6\n",
      "epoch [49/10000], loss:0.305007219315, patience: 6\n",
      "epoch [50/10000], loss:0.311870753765, patience: 7\n",
      "epoch [51/10000], loss:0.305900782347, patience: 7\n",
      "epoch [52/10000], loss:0.30699801445, patience: 8\n",
      "epoch [53/10000], loss:0.303301692009, patience: 8\n",
      "epoch [54/10000], loss:0.300887733698, patience: 8\n",
      "epoch [55/10000], loss:0.301257818937, patience: 9\n",
      "epoch [56/10000], loss:0.299373239279, patience: 9\n",
      "epoch [57/10000], loss:0.300050646067, patience: 10\n",
      "'AE' object has no attribute 'transorm'\n",
      "Checking Method: Pattern Search MDS\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MDS:Starting Error: 56293989293.6\n",
      "INFO:MDS:Epoch took: 20.6644258499\n",
      "INFO:MDS:Turn 1: Radius 32: (prev, error decrease, error): (56293989293.6, 49001607390.6, 7292381903.01)\n",
      "INFO:MDS:Epoch took: 21.7581989765\n",
      "INFO:MDS:Turn 2: Radius 32: (prev, error decrease, error): (7292381903.01, 5300749349.09, 1991632553.92)\n",
      "INFO:MDS:Epoch took: 22.2926840782\n",
      "INFO:MDS:Turn 3: Radius 32: (prev, error decrease, error): (1991632553.92, 256110532.903, 1735522021.01)\n",
      "INFO:MDS:Epoch took: 21.6373939514\n",
      "INFO:MDS:Turn 4: Radius 32: (prev, error decrease, error): (1735522021.01, 253933893.817, 1481588127.2)\n",
      "INFO:MDS:Epoch took: 20.7192971706\n",
      "INFO:MDS:Turn 5: Radius 32: (prev, error decrease, error): (1481588127.2, 116088840.907, 1365499286.29)\n",
      "INFO:MDS:Epoch took: 21.9112110138\n",
      "INFO:MDS:Turn 6: Radius 32: (prev, error decrease, error): (1365499286.29, -4972011.76016, 1370471298.05)\n",
      "INFO:MDS:Epoch took: 22.213037014\n",
      "INFO:MDS:Turn 7: Radius 16.0: (prev, error decrease, error): (1370471298.05, 681609195.51, 688862102.54)\n",
      "INFO:MDS:Epoch took: 21.4337749481\n",
      "INFO:MDS:Turn 8: Radius 16.0: (prev, error decrease, error): (688862102.54, 127807229.915, 561054872.625)\n",
      "INFO:MDS:Epoch took: 20.6940009594\n",
      "INFO:MDS:Turn 9: Radius 16.0: (prev, error decrease, error): (561054872.625, 37010284.3559, 524044588.269)\n",
      "INFO:MDS:Epoch took: 20.6110868454\n",
      "INFO:MDS:Turn 10: Radius 16.0: (prev, error decrease, error): (524044588.269, 54497289.7014, 469547298.567)\n",
      "INFO:MDS:Epoch took: 20.6241900921\n",
      "INFO:MDS:Turn 11: Radius 16.0: (prev, error decrease, error): (469547298.567, 14335197.7852, 455212100.782)\n",
      "INFO:MDS:Epoch took: 20.6590299606\n",
      "INFO:MDS:Turn 12: Radius 16.0: (prev, error decrease, error): (455212100.782, 15041905.5285, 440170195.254)\n",
      "INFO:MDS:Epoch took: 21.1042890549\n",
      "INFO:MDS:Turn 13: Radius 16.0: (prev, error decrease, error): (440170195.254, -772754.000904, 440942949.254)\n",
      "INFO:MDS:Epoch took: 20.8878600597\n",
      "INFO:MDS:Turn 14: Radius 8.0: (prev, error decrease, error): (440942949.254, 90117326.8709, 350825622.384)\n",
      "INFO:MDS:Epoch took: 20.6436779499\n",
      "INFO:MDS:Turn 15: Radius 8.0: (prev, error decrease, error): (350825622.384, 35522967.2961, 315302655.087)\n",
      "INFO:MDS:Epoch took: 20.6809082031\n",
      "INFO:MDS:Turn 16: Radius 8.0: (prev, error decrease, error): (315302655.087, 16811612.8689, 298491042.219)\n",
      "INFO:MDS:Epoch took: 21.0195651054\n",
      "INFO:MDS:Turn 17: Radius 8.0: (prev, error decrease, error): (298491042.219, 14568146.5037, 283922895.715)\n",
      "INFO:MDS:Epoch took: 20.7864379883\n",
      "INFO:MDS:Turn 18: Radius 8.0: (prev, error decrease, error): (283922895.715, 10031023.9043, 273891871.811)\n",
      "INFO:MDS:Epoch took: 20.6744198799\n",
      "INFO:MDS:Turn 19: Radius 8.0: (prev, error decrease, error): (273891871.811, 6993475.32274, 266898396.488)\n",
      "INFO:MDS:Epoch took: 21.2412278652\n",
      "INFO:MDS:Turn 20: Radius 8.0: (prev, error decrease, error): (266898396.488, 5132101.66586, 261766294.822)\n",
      "INFO:MDS:Epoch took: 20.6621251106\n",
      "INFO:MDS:Turn 21: Radius 8.0: (prev, error decrease, error): (261766294.822, 3728086.46652, 258038208.355)\n",
      "INFO:MDS:Epoch took: 20.8572199345\n",
      "INFO:MDS:Turn 22: Radius 8.0: (prev, error decrease, error): (258038208.355, 2652602.5445, 255385605.811)\n",
      "INFO:MDS:Epoch took: 20.6937348843\n",
      "INFO:MDS:Turn 23: Radius 8.0: (prev, error decrease, error): (255385605.811, 1963163.33304, 253422442.478)\n",
      "INFO:MDS:Epoch took: 22.0792219639\n",
      "INFO:MDS:Turn 24: Radius 8.0: (prev, error decrease, error): (253422442.478, 1437373.92832, 251985068.55)\n",
      "INFO:MDS:Epoch took: 22.7988240719\n",
      "INFO:MDS:Turn 25: Radius 8.0: (prev, error decrease, error): (251985068.55, 893793.198849, 251091275.351)\n",
      "INFO:MDS:Epoch took: 21.5589818954\n",
      "INFO:MDS:Turn 26: Radius 8.0: (prev, error decrease, error): (251091275.351, 1243172.04083, 249848103.31)\n",
      "INFO:MDS:Epoch took: 22.008906126\n",
      "INFO:MDS:Turn 27: Radius 8.0: (prev, error decrease, error): (249848103.31, 673906.173931, 249174197.136)\n",
      "INFO:MDS:Epoch took: 21.7083311081\n",
      "INFO:MDS:Turn 28: Radius 8.0: (prev, error decrease, error): (249174197.136, 575556.701573, 248598640.434)\n",
      "INFO:MDS:Epoch took: 21.5311200619\n",
      "INFO:MDS:Turn 29: Radius 8.0: (prev, error decrease, error): (248598640.434, 195139.670131, 248403500.764)\n",
      "INFO:MDS:Epoch took: 21.2696008682\n",
      "INFO:MDS:Turn 30: Radius 8.0: (prev, error decrease, error): (248403500.764, 396240.778391, 248007259.986)\n",
      "INFO:MDS:Epoch took: 21.542994976\n",
      "INFO:MDS:Turn 31: Radius 8.0: (prev, error decrease, error): (248007259.986, 44198.6846388, 247963061.301)\n",
      "INFO:MDS:Epoch took: 20.7269449234\n",
      "INFO:MDS:Turn 32: Radius 4.0: (prev, error decrease, error): (247963061.301, 14961912.2163, 233001149.085)\n",
      "INFO:MDS:Epoch took: 20.6922221184\n",
      "INFO:MDS:Turn 33: Radius 4.0: (prev, error decrease, error): (233001149.085, 14531865.0672, 218469284.018)\n",
      "INFO:MDS:Epoch took: 20.6538500786\n",
      "INFO:MDS:Turn 34: Radius 4.0: (prev, error decrease, error): (218469284.018, 9019239.78102, 209450044.237)\n",
      "INFO:MDS:Epoch took: 20.6838788986\n",
      "INFO:MDS:Turn 35: Radius 4.0: (prev, error decrease, error): (209450044.237, 7152311.76709, 202297732.47)\n",
      "INFO:MDS:Epoch took: 21.9091768265\n",
      "INFO:MDS:Turn 36: Radius 4.0: (prev, error decrease, error): (202297732.47, 5878334.79253, 196419397.677)\n",
      "INFO:MDS:Epoch took: 20.8769960403\n",
      "INFO:MDS:Turn 37: Radius 4.0: (prev, error decrease, error): (196419397.677, 4835477.86588, 191583919.811)\n",
      "INFO:MDS:Epoch took: 20.8501160145\n",
      "INFO:MDS:Turn 38: Radius 4.0: (prev, error decrease, error): (191583919.811, 3980085.71343, 187603834.098)\n",
      "INFO:MDS:Epoch took: 20.8944559097\n",
      "INFO:MDS:Turn 39: Radius 4.0: (prev, error decrease, error): (187603834.098, 3319132.62662, 184284701.471)\n",
      "INFO:MDS:Epoch took: 21.1902480125\n",
      "INFO:MDS:Turn 40: Radius 4.0: (prev, error decrease, error): (184284701.471, 2922840.44708, 181361861.024)\n",
      "INFO:MDS:Epoch took: 22.4469161034\n",
      "INFO:MDS:Turn 41: Radius 4.0: (prev, error decrease, error): (181361861.024, 2803093.11378, 178558767.91)\n",
      "INFO:MDS:Epoch took: 23.9698731899\n",
      "INFO:MDS:Turn 42: Radius 4.0: (prev, error decrease, error): (178558767.91, 2430139.27662, 176128628.634)\n",
      "INFO:MDS:Epoch took: 20.8217411041\n",
      "INFO:MDS:Turn 43: Radius 4.0: (prev, error decrease, error): (176128628.634, 2102656.10627, 174025972.527)\n",
      "INFO:MDS:Epoch took: 20.7603309155\n",
      "INFO:MDS:Turn 44: Radius 4.0: (prev, error decrease, error): (174025972.527, 1762918.11139, 172263054.416)\n",
      "INFO:MDS:Epoch took: 20.8657619953\n",
      "INFO:MDS:Turn 45: Radius 4.0: (prev, error decrease, error): (172263054.416, 1678493.02193, 170584561.394)\n",
      "INFO:MDS:Epoch took: 20.6389229298\n",
      "INFO:MDS:Turn 46: Radius 4.0: (prev, error decrease, error): (170584561.394, 1552314.68265, 169032246.712)\n",
      "INFO:MDS:Epoch took: 21.1800789833\n",
      "INFO:MDS:Turn 47: Radius 4.0: (prev, error decrease, error): (169032246.712, 1336472.95381, 167695773.758)\n",
      "INFO:MDS:Epoch took: 20.7560091019\n",
      "INFO:MDS:Turn 48: Radius 4.0: (prev, error decrease, error): (167695773.758, 1149932.11985, 166545841.638)\n",
      "INFO:MDS:Epoch took: 20.6388390064\n",
      "INFO:MDS:Turn 49: Radius 4.0: (prev, error decrease, error): (166545841.638, 920954.672429, 165624886.965)\n",
      "INFO:MDS:Epoch took: 20.6921200752\n",
      "INFO:MDS:Turn 50: Radius 4.0: (prev, error decrease, error): (165624886.965, 919333.725178, 164705553.24)\n",
      "INFO:MDS:Epoch took: 20.6913850307\n",
      "INFO:MDS:Turn 51: Radius 4.0: (prev, error decrease, error): (164705553.24, 814789.385935, 163890763.854)\n",
      "INFO:MDS:Epoch took: 20.6676290035\n",
      "INFO:MDS:Turn 52: Radius 4.0: (prev, error decrease, error): (163890763.854, 796209.774525, 163094554.08)\n",
      "INFO:MDS:Epoch took: 20.7107639313\n",
      "INFO:MDS:Turn 53: Radius 4.0: (prev, error decrease, error): (163094554.08, 589735.224775, 162504818.855)\n",
      "INFO:MDS:Epoch took: 20.743666172\n",
      "INFO:MDS:Turn 54: Radius 4.0: (prev, error decrease, error): (162504818.855, 511497.929128, 161993320.926)\n",
      "INFO:MDS:Epoch took: 20.7440629005\n",
      "INFO:MDS:Turn 55: Radius 4.0: (prev, error decrease, error): (161993320.926, 458438.183524, 161534882.742)\n",
      "INFO:MDS:Epoch took: 20.9367089272\n",
      "INFO:MDS:Turn 56: Radius 4.0: (prev, error decrease, error): (161534882.742, 462237.844787, 161072644.898)\n",
      "INFO:MDS:Epoch took: 21.857088089\n",
      "INFO:MDS:Turn 57: Radius 4.0: (prev, error decrease, error): (161072644.898, 372841.489202, 160699803.408)\n",
      "INFO:MDS:Epoch took: 20.7047078609\n",
      "INFO:MDS:Turn 58: Radius 4.0: (prev, error decrease, error): (160699803.408, 297185.555916, 160402617.852)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MDS:Epoch took: 21.9875910282\n",
      "INFO:MDS:Turn 59: Radius 4.0: (prev, error decrease, error): (160402617.852, 260638.158177, 160141979.694)\n",
      "INFO:MDS:Epoch took: 20.9490330219\n",
      "INFO:MDS:Turn 60: Radius 4.0: (prev, error decrease, error): (160141979.694, 263053.039591, 159878926.655)\n",
      "INFO:MDS:Epoch took: 20.6846671104\n",
      "INFO:MDS:Turn 61: Radius 4.0: (prev, error decrease, error): (159878926.655, 264979.39524, 159613947.259)\n",
      "INFO:MDS:Epoch took: 20.7139220238\n",
      "INFO:MDS:Turn 62: Radius 4.0: (prev, error decrease, error): (159613947.259, 224961.784242, 159388985.475)\n",
      "INFO:MDS:Epoch took: 20.7003281116\n",
      "INFO:MDS:Turn 63: Radius 4.0: (prev, error decrease, error): (159388985.475, 154469.284531, 159234516.191)\n",
      "INFO:MDS:Epoch took: 20.8918869495\n",
      "INFO:MDS:Turn 64: Radius 4.0: (prev, error decrease, error): (159234516.191, 178171.332769, 159056344.858)\n",
      "INFO:MDS:Epoch took: 22.6670110226\n",
      "INFO:MDS:Turn 65: Radius 4.0: (prev, error decrease, error): (159056344.858, 132865.970275, 158923478.888)\n",
      "INFO:MDS:Epoch took: 20.7086029053\n",
      "INFO:MDS:Turn 66: Radius 4.0: (prev, error decrease, error): (158923478.888, 161583.273814, 158761895.614)\n",
      "INFO:MDS:Epoch took: 20.6446731091\n",
      "INFO:MDS:Turn 67: Radius 4.0: (prev, error decrease, error): (158761895.614, 124617.670474, 158637277.943)\n",
      "INFO:MDS:Epoch took: 20.6558899879\n",
      "INFO:MDS:Turn 68: Radius 4.0: (prev, error decrease, error): (158637277.943, 125843.279391, 158511434.664)\n",
      "INFO:MDS:Epoch took: 21.4076628685\n",
      "INFO:MDS:Turn 69: Radius 4.0: (prev, error decrease, error): (158511434.664, 77217.7373067, 158434216.927)\n",
      "INFO:MDS:Epoch took: 21.9137670994\n",
      "INFO:MDS:Turn 70: Radius 2.0: (prev, error decrease, error): (158434216.927, 3865402.94092, 154568813.986)\n",
      "INFO:MDS:Epoch took: 23.0915589333\n",
      "INFO:MDS:Turn 71: Radius 2.0: (prev, error decrease, error): (154568813.986, 5619391.15594, 148949422.83)\n",
      "INFO:MDS:Epoch took: 20.7692551613\n",
      "INFO:MDS:Turn 72: Radius 2.0: (prev, error decrease, error): (148949422.83, 4018622.97565, 144930799.854)\n",
      "INFO:MDS:Epoch took: 20.7558948994\n",
      "INFO:MDS:Turn 73: Radius 2.0: (prev, error decrease, error): (144930799.854, 2769930.861, 142160868.993)\n",
      "INFO:MDS:Epoch took: 20.815392971\n",
      "INFO:MDS:Turn 74: Radius 2.0: (prev, error decrease, error): (142160868.993, 2169088.07731, 139991780.916)\n",
      "INFO:MDS:Epoch took: 21.057571888\n",
      "INFO:MDS:Turn 75: Radius 2.0: (prev, error decrease, error): (139991780.916, 1981508.04454, 138010272.871)\n",
      "INFO:MDS:Epoch took: 20.7148809433\n",
      "INFO:MDS:Turn 76: Radius 2.0: (prev, error decrease, error): (138010272.871, 1847447.11805, 136162825.753)\n",
      "INFO:MDS:Epoch took: 20.708304882\n",
      "INFO:MDS:Turn 77: Radius 2.0: (prev, error decrease, error): (136162825.753, 1695209.03854, 134467616.715)\n",
      "INFO:MDS:Epoch took: 20.6261892319\n",
      "INFO:MDS:Turn 78: Radius 2.0: (prev, error decrease, error): (134467616.715, 1536353.86841, 132931262.846)\n",
      "INFO:MDS:Epoch took: 20.6565861702\n",
      "INFO:MDS:Turn 79: Radius 2.0: (prev, error decrease, error): (132931262.846, 1433340.47794, 131497922.368)\n",
      "INFO:MDS:Epoch took: 20.7274188995\n",
      "INFO:MDS:Turn 80: Radius 2.0: (prev, error decrease, error): (131497922.368, 1385671.73439, 130112250.634)\n",
      "INFO:MDS:Epoch took: 20.5079729557\n",
      "INFO:MDS:Turn 81: Radius 2.0: (prev, error decrease, error): (130112250.634, 1289756.47879, 128822494.155)\n",
      "INFO:MDS:Epoch took: 20.9399590492\n",
      "INFO:MDS:Turn 82: Radius 2.0: (prev, error decrease, error): (128822494.155, 1220465.59784, 127602028.557)\n",
      "INFO:MDS:Epoch took: 20.7530801296\n",
      "INFO:MDS:Turn 83: Radius 2.0: (prev, error decrease, error): (127602028.557, 1113547.7708, 126488480.787)\n",
      "INFO:MDS:Epoch took: 20.7460620403\n",
      "INFO:MDS:Turn 84: Radius 2.0: (prev, error decrease, error): (126488480.787, 1060088.22841, 125428392.558)\n",
      "INFO:MDS:Epoch took: 21.4321079254\n",
      "INFO:MDS:Turn 85: Radius 2.0: (prev, error decrease, error): (125428392.558, 980503.016363, 124447889.542)\n",
      "INFO:MDS:Epoch took: 20.9773190022\n",
      "INFO:MDS:Turn 86: Radius 2.0: (prev, error decrease, error): (124447889.542, 937823.462069, 123510066.08)\n",
      "INFO:MDS:Epoch took: 20.7558729649\n",
      "INFO:MDS:Turn 87: Radius 2.0: (prev, error decrease, error): (123510066.08, 919951.224945, 122590114.855)\n",
      "INFO:MDS:Epoch took: 20.7920901775\n",
      "INFO:MDS:Turn 88: Radius 2.0: (prev, error decrease, error): (122590114.855, 857005.197809, 121733109.657)\n",
      "INFO:MDS:Epoch took: 20.632117033\n",
      "INFO:MDS:Turn 89: Radius 2.0: (prev, error decrease, error): (121733109.657, 840237.59853, 120892872.058)\n",
      "INFO:MDS:Epoch took: 20.6214799881\n",
      "INFO:MDS:Turn 90: Radius 2.0: (prev, error decrease, error): (120892872.058, 819120.299107, 120073751.759)\n",
      "INFO:MDS:Epoch took: 20.6509349346\n",
      "INFO:MDS:Turn 91: Radius 2.0: (prev, error decrease, error): (120073751.759, 761807.346938, 119311944.412)\n",
      "INFO:MDS:Epoch took: 20.5551581383\n",
      "INFO:MDS:Turn 92: Radius 2.0: (prev, error decrease, error): (119311944.412, 743523.669249, 118568420.743)\n",
      "INFO:MDS:Epoch took: 20.6491761208\n",
      "INFO:MDS:Turn 93: Radius 2.0: (prev, error decrease, error): (118568420.743, 680301.640013, 117888119.103)\n",
      "INFO:MDS:Epoch took: 20.6495580673\n",
      "INFO:MDS:Turn 94: Radius 2.0: (prev, error decrease, error): (117888119.103, 668313.907643, 117219805.195)\n",
      "INFO:MDS:Epoch took: 20.6375460625\n",
      "INFO:MDS:Turn 95: Radius 2.0: (prev, error decrease, error): (117219805.195, 625753.014711, 116594052.181)\n",
      "INFO:MDS:Epoch took: 20.6533358097\n",
      "INFO:MDS:Turn 96: Radius 2.0: (prev, error decrease, error): (116594052.181, 587585.036369, 116006467.144)\n",
      "INFO:MDS:Epoch took: 20.6440620422\n",
      "INFO:MDS:Turn 97: Radius 2.0: (prev, error decrease, error): (116006467.144, 549519.668847, 115456947.476)\n",
      "INFO:MDS:Epoch took: 20.6907598972\n",
      "INFO:MDS:Turn 98: Radius 2.0: (prev, error decrease, error): (115456947.476, 513349.563593, 114943597.912)\n",
      "INFO:MDS:Epoch took: 21.6106719971\n",
      "INFO:MDS:Turn 99: Radius 2.0: (prev, error decrease, error): (114943597.912, 495968.834811, 114447629.077)\n",
      "INFO:MDS:Epoch took: 22.1117949486\n",
      "INFO:MDS:Turn 100: Radius 2.0: (prev, error decrease, error): (114447629.077, 485783.754435, 113961845.323)\n",
      "INFO:MDS:Avg epoch time: 21.0813142061\n",
      "INFO:MDS:Ending Error: 113961845.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDS.fit_transform took: 2109.20285583 sec\n",
      "Checking Method: Truncated SVD\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n",
      "Checking Method: Spectral Embedding\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n",
      "Checking Method: LLE\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n",
      "Checking Method: Modified LLE\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n",
      "Checking Method: ISOMAP\n",
      "Reducing Input from Dimension: 2014 to a Lower Embedded Manifold with dimensions: 50...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_IEMOCAP_session_KNN() takes exactly 4 arguments (5 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9916968c838f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIEMOCAP_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fused_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_feats_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl_feats_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mreduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_DR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods_to_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluded_sessions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dr50-fused-iemocap.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moriginal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_IEMOCAP_session_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2014\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Original Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluded_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfused_results1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_IEMOCAP_session_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluded_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_IEMOCAP_session_KNN() takes exactly 4 arguments (5 given)"
     ]
    }
   ],
   "source": [
    "included_sessions=['Ses01', 'Ses02', 'Ses03', 'Ses04', 'Ses05']\n",
    "methods_to_test = ['Autoencoder', 'Pattern Search MDS', 'Truncated SVD', 'Spectral Embedding', \n",
    "                   'LLE', 'Modified LLE', 'ISOMAP']   \n",
    "target_dims = [50]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p, nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr50-fused-iemocap.p')\n",
    "original_results = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)\n",
    "fused_results1 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [100]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p, nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr100-fused-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "fused_results2 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [25, 10, 5, 3, 2]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p, nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr25-10-5-3-2-fused-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "fused_results3 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for target_dim in sorted(original_results.keys()):\n",
    "    df = original_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "\n",
    "for target_dim in sorted(fused_results1.keys()):\n",
    "    df = fused_results1[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(fused_results2.keys()):\n",
    "    df = fused_results2[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(fused_results3.keys()):\n",
    "    df = fused_results3[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr50-rqa-iemocap.p')\n",
    "original_results = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)\n",
    "nl_results1 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [100]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p, nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr100-rqa-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "nl_results2 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [25, 10, 5, 3, 2]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p, nl_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr25-10-5-3-2-rqa-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "nl_results3 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for target_dim in sorted(original_results.keys()):\n",
    "    df = original_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "\n",
    "for target_dim in sorted(nl_results1.keys()):\n",
    "    df = nl_results1[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(nl_results2.keys()):\n",
    "    df = nl_results2[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(nl_results3.keys()):\n",
    "    df = nl_results3[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr50-emobase-iemocap.p')\n",
    "original_results = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)\n",
    "emobase_results1 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [100]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr100-emobase-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "emobase_results2 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dims = [25, 10, 5, 3, 2]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([l_feats_p])\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, included_sessions, saveto='dr25-10-5-3-2-emobase-iemocap.p')\n",
    "# original_results = run_IEMOCAP_session_KNN(n_neighbors, [2014], ['Original Data'], data_dic, included_sessions)\n",
    "emobase_results3 = run_IEMOCAP_session_KNN(n_neighbors, reduced, data_dic, included_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for target_dim in sorted(original_results.keys()):\n",
    "    df = original_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "\n",
    "for target_dim in sorted(emobase_results1.keys()):\n",
    "    df = emobase_results1[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(emobase_results2.keys()):\n",
    "    df = emobase_results2[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    \n",
    "for target_dim in sorted(emobase_results3.keys()):\n",
    "    df = emobase_results3[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment for EmoDB Speaker independent Experiments\n",
    "def get_dataset_for_all_speakers(features_dic):\n",
    "    speaker_indices = {}\n",
    "    x_all_list = []\n",
    "    Y_all = []\n",
    "    prev_ind = 0\n",
    "    for te_speaker, te_data in features_dic.items():  \n",
    "        x_all_list.append(te_data['x'])\n",
    "        Y_all += te_data['y']\n",
    "        this_speaker_samples = len(te_data['y'])\n",
    "        \n",
    "        speaker_indices[te_speaker] = (prev_ind, prev_ind + this_speaker_samples)\n",
    "        prev_ind += this_speaker_samples\n",
    "        X_all = np.concatenate(x_all_list, axis=0)\n",
    "    number_of_speakers = len(features_dic.keys())\n",
    "    return X_all, Y_all, speaker_indices, number_of_speakers\n",
    "\n",
    "def generate_speaker_independent_folds(X_all, Y_all, features_dic, speaker_indices):\n",
    "    sorted_speakers = sorted(speaker_indices.keys())\n",
    "    for (te_speaker, (st, et)) in speaker_indices.items():\n",
    "        Y_te = Y_all[st:et]\n",
    "        X_te = X_all[st:et, :]\n",
    "        \n",
    "        x_tr_list = []\n",
    "        Y_tr = []\n",
    "        for sp in sorted_speakers:\n",
    "            if sp == te_speaker:\n",
    "                continue\n",
    "            st, et = speaker_indices[sp] \n",
    "            x_tr_list.append(X_all[st:et, :])\n",
    "            Y_tr += Y_all[st:et]\n",
    "        X_tr = np.concatenate(x_tr_list, axis=0)    \n",
    "        \n",
    "        yield te_speaker, X_te, Y_te, X_tr, Y_tr \n",
    "\n",
    "\n",
    "        \n",
    "def run_DR(target_dims, methods_to_test, data_dic, saveto=None):\n",
    "    save_file = os.path.join('../', 'cache', saveto)\n",
    "    if saveto is not None os.path.isfile(save_file):\n",
    "        with open(save_file, 'rb') as fd:\n",
    "            reduced = pickle.load(fd)\n",
    "        return reduced\n",
    "    X_all, Y_all, speaker_indices, number_of_sessions = get_dataset_for_all_speakers(data_dic)\n",
    "    # normalize the input vectors \n",
    "    X_high = StandardScaler().fit_transform(X_all)\n",
    "    \n",
    "    print(X_high.shape)\n",
    "    \n",
    "    reduced = {}\n",
    "    original_dim = X_all.shape[1]\n",
    "    for target_dim in target_dims:\n",
    "        reduced[target_dim] = {}\n",
    "        manifold_methods = get_manifold_methods(original_dim, target_dim)\n",
    "    #     methods_to_test = manifold_methods.keys()\n",
    "        methods_metrics = {}\n",
    "        for selected_method in methods_to_test:            \n",
    "            print('Checking Method: {}'.format(selected_method))\n",
    "            \n",
    "            print('Reducing Input from Dimension: {} to a Lower Embedded Manifold with dimensions: {}...'.format(\n",
    "                   X_high.shape[1], target_dim))\n",
    "            try:\n",
    "                obj = manifold_methods[selected_method]['object']\n",
    "                if selected_method == 'Pattern Search MDS':\n",
    "                    d_goal = multidimensional.common.DISTANCE_MATRIX(X_high.astype(np.float64))\n",
    "#                    d_goal = 1.0 - np.corrcoef(X_high.astype(np.float64))\n",
    "#                    np.fill_diagonal(d_goal, 0)\n",
    "                    X_low = obj.fit_transform(d_goal)\n",
    "                else:\n",
    "                    X_low = obj.fit_transform(X_high)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                X_low = None\n",
    "            reduced[target_dim][selected_method] = X_low\n",
    "    if saveto is not None:\n",
    "        with open(save_file, saveto), 'wb') as fd:\n",
    "            pickle.dump(reduced, fd)\n",
    "    return reduced\n",
    "\n",
    "def run_speaker_independent_KNN(n_neighbors, reduced, data_dic):\n",
    "\n",
    "    X_all, Y_all, speaker_indices, number_of_speakers = get_dataset_for_all_speakers(data_dic)\n",
    "    df_results = {}\n",
    "    # normalize the input vectors \n",
    "    X_high = StandardScaler().fit_transform(X_all)\n",
    "    \n",
    "    print X_high.shape \n",
    "\n",
    "    for target_dim, methods in reduced.iteritems():\n",
    "        for selected_method, X_low in methods.iteritems():\n",
    "            print('Checking Method: {}'.format(selected_method))\n",
    "            metrics_l = {'uw_acc': dict([(k, 0.0) for k in n_neighbors]), 'w_acc': dict([(k, 0.0) for k in n_neighbors])}\n",
    "            if X_low is None:\n",
    "                methods_metrics[selected_method+' UA'] = metrics_l['uw_acc']\n",
    "                methods_metrics[selected_method+' WA'] = metrics_l['w_acc']\n",
    "                continue             \n",
    "            \n",
    "            for k in n_neighbors:\n",
    "                knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='brute', leaf_size=30, \n",
    "                                           p=2, metric='minkowski', metric_params=None, n_jobs=8)\n",
    "\n",
    "                speaker_folds = generate_speaker_independent_folds(X_low, Y_all, data_dic, speaker_indices)\n",
    "                for te_speaker, X_te, Y_te, X_tr, Y_tr in speaker_folds:                    \n",
    "                    try:\n",
    "                        knn.fit(X_tr, Y_tr) \n",
    "                        Y_predicted = knn.predict(X_te)\n",
    "\n",
    "                        w_acc = accuracy_score(Y_predicted, Y_te)\n",
    "                        cmat = confusion_matrix(Y_te, Y_predicted)\n",
    "                        with np.errstate(divide='ignore'):\n",
    "                            uw_acc = (cmat.diagonal() / (1.0 * cmat.sum(axis=1) + 1e-6)).mean()\n",
    "                            if np.isnan(uw_acc):\n",
    "                                uw_acc = 0.\n",
    "                        w_acc = round(w_acc*100,0)\n",
    "                        uw_acc = round(uw_acc*100,)\n",
    "                        metrics_l['uw_acc'][k] += uw_acc/number_of_speakers\n",
    "                        metrics_l['w_acc'][k] += w_acc/number_of_speakers\n",
    "                    except:\n",
    "                        metrics_l['uw_acc'][k] += 0.\n",
    "                        metrics_l['w_acc'][k] += 0.\n",
    "                    \n",
    "            methods_metrics[selected_method+' UA'] = metrics_l['uw_acc']\n",
    "            methods_metrics[selected_method+' WA'] = metrics_l['w_acc']\n",
    "\n",
    "        df = pd.DataFrame.from_dict(methods_metrics, orient=\"index\")\n",
    "        df_results[target_dim] = df[sorted(df.columns)]\n",
    "        \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for Speaker Independent Experiments \n",
    "n_neighbors = np.arange(1, 40, 4)\n",
    "target_dims = [2, 5, 10, 25]\n",
    "\n",
    "# Find all appropriate files \n",
    "data_path = '/home/george/all_BERLIN_features/'\n",
    "berlin_l_feats_p = data_path + 'linear/BERLIN_linear_emobase2010'\n",
    "# nl_feats_l = glob.glob( IEMOCAP_data_path + '/utterance/*.dat')\n",
    "# nl_feats_p = nl_feats_l.pop()\n",
    "berlin_nl_feats_p = os.path.join(data_path, \n",
    "             'rqa/utterance/BERLIN-rqa-ad_hoc-tau-7-manhattan-recurrence_rate-0.15-dur-0.02-fs-16000.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_to_test = ['Autoencoder', 'Pattern Search MDS', 'MDS SMACOF','Truncated SVD', 'Spectral Embedding', 'LLE', \n",
    "                   'Modified LLE', 'ISOMAP']   \n",
    "# methods_to_test = ['Pattern Search MDS']\n",
    "# methods_to_test = ['Truncated SVD']\n",
    "\n",
    "target_dims = [100, 50, 25, 10, 5, 3, 2]\n",
    "# methods_to_test = ['Truncated SVD', 'Spectral Embedding']\n",
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_nl_feats_p])\n",
    "berlin_original_nl_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, saveto='dr-rqa-berlin.p')\n",
    "berlin_nl_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_l_feats_p])\n",
    "berlin_original_l_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, saveto='dr-emobase-berlin.p')\n",
    "berlin_l_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_l_feats_p, berlin_nl_feats_p])\n",
    "berlin_original_fused_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)\n",
    "reduced = run_DR(target_dims, methods_to_test, data_dic, saveto='dr-fused-berlin.p')\n",
    "berlin_fused_results = run_speaker_independent_KNN(n_neighbors, reduced, data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "print \"Using RQA Feature Set and Dimensionality Reduction...\"\n",
    "\n",
    "def latex_preformat_print(df):\n",
    "    methods = {}\n",
    "    for ind in df.index.values:\n",
    "        if not ind[:-3] in methods and ind[-2:] == 'WA':\n",
    "            methods[ind[:-3]] = list(df[[1,5,9,13,17,21]].loc[ind])\n",
    "    for ind in df.index.values:\n",
    "        if ind[-2:] == 'UA':\n",
    "            methods[ind[:-3]] += list(df[[1,5,9,13,17,21]].loc[ind])\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(methods, orient=\"index\")\n",
    "    print df.to_latex()\n",
    "\n",
    "for target_dim in sorted(berlin_original_nl_results.keys()):\n",
    "    df = berlin_original_nl_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)\n",
    "    \n",
    "for target_dim in sorted(berlin_nl_results.keys()):\n",
    "    df = berlin_nl_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "print \"Using Emobase Features and Dimensionality Reduction...\"\n",
    "\n",
    "for target_dim in sorted(berlin_original_l_results.keys()):\n",
    "    df = berlin_original_l_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)\n",
    "\n",
    "for target_dim in sorted(berlin_l_results.keys()):\n",
    "    df = berlin_l_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "print \"Using Fused Features and Dimensionality Reduction...\"\n",
    "\n",
    "for target_dim in sorted(berlin_original_fused_results.keys()):\n",
    "    df = berlin_original_fused_results[target_dim]\n",
    "    print \"Using Original Data\"\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)\n",
    "\n",
    "for target_dim in sorted(berlin_fused_results.keys()):\n",
    "    df = berlin_fused_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
