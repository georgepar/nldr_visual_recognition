{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the appropriate modules \n",
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "sys.path.append('../')\n",
    "import config\n",
    "sys.path.append(config.BASE_PATH)\n",
    "from dataloader import fused_features_IEMOCAP as IEMOCAP_loader\n",
    "\n",
    "sys.path.append(config.PATTERN_SEARCH_MDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment for EmoDB Speaker independent Experiments\n",
    "def get_emodb_dataset(features_dic):\n",
    "    speaker_indices = {}\n",
    "    x_all_list = []\n",
    "    Y_all = []\n",
    "    prev_ind = 0\n",
    "    for te_speaker, te_data in features_dic.items():  \n",
    "        x_all_list.append(te_data['x'])\n",
    "        Y_all += te_data['y']\n",
    "        this_speaker_samples = len(te_data['y'])\n",
    "        \n",
    "        speaker_indices[te_speaker] = (prev_ind, prev_ind + this_speaker_samples)\n",
    "        prev_ind += this_speaker_samples\n",
    "        X_all = np.concatenate(x_all_list, axis=0)\n",
    "    number_of_speakers = len(features_dic.keys())\n",
    "    return X_all, Y_all, speaker_indices, number_of_speakers\n",
    "\n",
    "def fuse_excited_happiness(l):\n",
    "    return ['happy + excited' \n",
    "            if (e == 'excited' or e == 'happy') \n",
    "            else e for e in l ]\n",
    "\n",
    "def get_iemocap_dataset(features_dic):\n",
    "    speaker_indices = {}\n",
    "    x_all_list = []\n",
    "    Y_all = []\n",
    "    prev_ind = 0\n",
    "    sessions = []\n",
    "    for te_speaker, te_data in features_dic.items():  \n",
    "        ses_name = te_speaker[:-1]\n",
    "        sessions.append(ses_name)\n",
    "        x_all_list.append(te_data['x'])\n",
    "        Y_all += te_data['y']\n",
    "        this_speaker_samples = len(te_data['y'])\n",
    "        \n",
    "        speaker_indices[te_speaker] = (prev_ind, prev_ind + this_speaker_samples)\n",
    "        prev_ind += this_speaker_samples\n",
    "        X_all = np.concatenate(x_all_list, axis=0)\n",
    "    return X_all, fuse_excited_happiness(Y_all), speaker_indices, len(set(sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class IEMOCAPData(Dataset):\n",
    "    def __init__(self, X,):\n",
    "        self.X_high = X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X_high.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_high[idx]\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, hidden_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, in_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        x = self.decoder(h)\n",
    "        return x, h\n",
    "\n",
    "\n",
    "class AE(object):\n",
    "    def __init__(self, original_dim, target_dim, batch_size=32, learning_rate=1e-4, num_epochs=10000, early_stop=10):\n",
    "        self.original_dim = original_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.early_stop = early_stop\n",
    "        self.dvc = 'cpu'\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        iemo_data = IEMOCAPData(X)\n",
    "\n",
    "        dataloader = DataLoader(iemo_data, batch_size=self.batch_size, shuffle=True)\n",
    "        model = autoencoder(self.original_dim, self.target_dim).to(self.dvc)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        patience = 0\n",
    "        prev_avg_loss = np.Inf\n",
    "        for epoch in range(self.num_epochs):\n",
    "            avg_loss= 0\n",
    "            data_loader = tqdm(iter(dataloader))\n",
    "\n",
    "            for data in data_loader:\n",
    "                data = torch.Tensor(data.type(torch.FloatTensor)).to(self.dvc)\n",
    "                # ===================forward=====================\n",
    "                output, hidden = model(data)\n",
    "        #         loss = criterion(output, data, hidden)\n",
    "                loss = criterion(output, data)\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.detach().item()\n",
    "            # ===================log========================\n",
    "            if avg_loss > prev_avg_loss:\n",
    "                patience += 1\n",
    "            data_loader.set_description(\n",
    "            'Epoch: {}; Loss: {:.10f}; patience: {}'.format(\n",
    "                epoch + 1,\n",
    "                avg_loss / len(data_loader),\n",
    "                patience,\n",
    "            ))\n",
    "            if patience >= self.early_stop:\n",
    "                break\n",
    "            prev_avg_loss = avg_loss\n",
    "        self.model = model\n",
    "        return model\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.model(torch.Tensor(X).type(torch.FloatTensor).to(self.dvc)).numpy()\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.model = self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all avaiulable Manifold Methods\n",
    "import multidimensional\n",
    "import multidimensional.common\n",
    "import multidimensional.mds \n",
    "import multidimensional.smacof\n",
    "import multidimensional.mds_utils as mds_utils\n",
    "from sklearn import manifold, decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS as SMACOF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class IdentityData(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        return x\n",
    "\n",
    "def get_manifold_methods(original_dim, target_dim):\n",
    "    method_n_comp = 66\n",
    "    radius_barrier = 1e-3\n",
    "    explore_dim_percent = 1\n",
    "    starting_radius = 32\n",
    "    max_turns = 500\n",
    "    point_filter = (multidimensional.point_filters.FixedStochasticFilter(keep_percent=1, recalculate_each=10))\n",
    "    radius_update = (multidimensional.radius_updates.AdaRadiusHalving(tolerance=.5*1e-3, burnout_tolerance=100000))\n",
    "\n",
    "    mds_obj = multidimensional.mds.MDS(target_dim, point_filter, radius_update, starting_radius=starting_radius, \n",
    "                                       radius_barrier=radius_barrier,\n",
    "                max_turns=max_turns, keep_history=False,\n",
    "                explore_dim_percent=explore_dim_percent)\n",
    "\n",
    "    manifold_methods = {\n",
    "        'Pattern Search MDS': { 'results': {}, 'object': multidimensional.mds.MDS(target_dim, point_filter, \n",
    "                                                         radius_update, starting_radius=starting_radius, \n",
    "                                                         radius_barrier=radius_barrier, max_turns=max_turns, \n",
    "                                                         keep_history=False,\n",
    "                                                         dissimilarities='precomputed',\n",
    "                                                         explore_dim_percent=explore_dim_percent)},\n",
    "        'MDS SMACOF': { 'results': {}, 'object': SMACOF(n_components=target_dim, n_init=1, \n",
    "                                                 max_iter=max_turns, dissimilarity='euclidean', n_jobs=8)},\n",
    "        'LTSA': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='ltsa',n_jobs=8)},\n",
    "        'Modified LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='modified',n_jobs=8)},\n",
    "        'Hessian LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='hessian',n_jobs=8)},\n",
    "        'LLE': { 'results': {}, 'object': manifold.LocallyLinearEmbedding(method_n_comp, target_dim, \n",
    "                                           eigen_solver='auto', method='standard',n_jobs=8)},\n",
    "        'PCA': { 'results': {}, 'object': PCA(n_components=target_dim)},\n",
    "        'Spectral Embedding': { 'results': {}, 'object': manifold.SpectralEmbedding(n_components=target_dim, \n",
    "                                                                                    n_jobs=8)},\n",
    "        'TSNE': { 'results': {}, 'object': manifold.TSNE(n_components=target_dim)},\n",
    "        'ISOMAP': { 'results': {}, 'object': manifold.Isomap(12, target_dim)},\n",
    "        'Original Data': { 'results': {}, 'object': IdentityData()},\n",
    "        'Autoencoder': { 'results': {}, 'object': AE(original_dim, target_dim) }\n",
    "\n",
    "    }\n",
    "    return manifold_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DR(target_dims, methods_to_test, X_all, saveto=None):\n",
    "    save_file = os.path.join('../', 'cache', saveto)\n",
    "    if saveto is not None and os.path.isfile(save_file):\n",
    "        with open(save_file, 'rb') as fd:\n",
    "            reduced = pickle.load(fd)\n",
    "        return reduced\n",
    "    # normalize the input vectors \n",
    "#     X_high = StandardScaler().fit_transform(X_all)\n",
    "    X_high = X_all\n",
    "    print(X_high.shape)\n",
    "    \n",
    "    reduced = {}\n",
    "    original_dim = X_all.shape[1]\n",
    "    for target_dim in target_dims:\n",
    "        reduced[target_dim] = {}\n",
    "        manifold_methods = get_manifold_methods(original_dim, target_dim)\n",
    "        methods_metrics = {}\n",
    "        for selected_method in methods_to_test:            \n",
    "            print('Running Method: {}'.format(selected_method))\n",
    "            \n",
    "            print('Reducing Input from Dimension: {} to a Lower Embedded Manifold with dimensions: {}...'.format(\n",
    "                   X_high.shape[1], target_dim))\n",
    "            try:\n",
    "                obj = manifold_methods[selected_method]['object']\n",
    "                if selected_method == 'Pattern Search MDS':\n",
    "                    d_goal = multidimensional.common.DISTANCE_MATRIX(X_high.astype(np.float64))\n",
    "    #                 d_goal = 1.0 - np.corrcoef(X_high.astype(np.float64))\n",
    "    #                 np.fill_diagonal(d_goal, 0)\n",
    "                    X_low = obj.fit_transform(d_goal)\n",
    "                else:\n",
    "                    X_low = obj.fit_transform(X_high)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                X_low = None\n",
    "            reduced[target_dim][selected_method] = X_low\n",
    "    if saveto is not None:\n",
    "        with open(save_file, 'wb') as fd:\n",
    "            pickle.dump(reduced, fd)\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def emodb_speaker_groups(speaker_indices, n_samples):\n",
    "    speaker_groups = np.zeros(n_samples, dtype=np.int)\n",
    "    for speaker, sp_rng in speaker_indices.items():\n",
    "        speaker_groups[sp_rng[0]:sp_rng[1]] = int(speaker)\n",
    "    return speaker_groups\n",
    "\n",
    "def iemocap_speaker_groups(speaker_indices, n_samples):\n",
    "    sessions = ['Ses01', 'Ses02', 'Ses03', 'Ses04', 'Ses05']\n",
    "    speaker_groups = np.zeros(n_samples, dtype=np.int)\n",
    "    for sp, ind in speaker_indices.items():\n",
    "        # sp = Ses0XM or Ses0XF\n",
    "        speaker_groups[ind[0]:ind[1]] = int(sp[-2])\n",
    "    return speaker_groups\n",
    "\n",
    "def knn_search(n_neighbors, X, y, speaker_groups):\n",
    "    if X is None:\n",
    "        return [0 for _ in range(len(n_neighbors))], [0 for _ in range(len(n_neighbors))], n_neighbors\n",
    "\n",
    "    clf_pipeline = Pipeline(steps=[\n",
    "        ('znorm', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier(p=2, metric='minkowski'))\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'knn__n_neighbors': n_neighbors,\n",
    "    }\n",
    "    outer_group = list(LeaveOneGroupOut().split(X, y, speaker_groups))\n",
    "    scorers = {\n",
    "        'w_acc': make_scorer(accuracy_score),\n",
    "        'uw_acc': make_scorer(balanced_accuracy_score)\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        clf_pipeline,\n",
    "        refit=False,\n",
    "        iid=False,\n",
    "        param_grid=param_grid,\n",
    "        cv=outer_group,\n",
    "        scoring=scorers,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    results = grid_search.fit(X, y).cv_results_\n",
    "    wa = results['mean_test_w_acc']\n",
    "    ua = results['mean_test_uw_acc']\n",
    "    neigh = [p['knn__n_neighbors'] for p in results['params']]\n",
    "    return wa, ua, neigh\n",
    "\n",
    "\n",
    "def run_knn_search(reduced, y_all, speaker_groups, saveto=None):\n",
    "    results = {}\n",
    "    for target_dim, methods in reduced.iteritems():\n",
    "        method_results = {}\n",
    "        for method, X_low in methods.iteritems():\n",
    "            wa, ua, n_neigh = knn_search(n_neighbors, X_low, y_all, speaker_groups)\n",
    "            method_results['{} WA'.format(method)] = dict(zip(n_neigh, wa))\n",
    "            method_results['{} UA'.format(method)] = dict(zip(n_neigh, ua))\n",
    "        df = pd.DataFrame.from_dict(method_results, orient='index')\n",
    "        df = df[sorted(df.columns)]\n",
    "        results[target_dim] = df\n",
    "    if saveto is not None:\n",
    "        with open(saveto, 'wb') as fd:\n",
    "            pickle.dump(results, fd)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_preformat_print(df):\n",
    "    methods = {}\n",
    "    for ind in df.index.values:\n",
    "        if not ind[:-3] in methods and ind[-2:] == 'WA':\n",
    "            methods[ind[:-3]] = list(df[[1,5,9,13,17,21]].loc[ind])\n",
    "    for ind in df.index.values:\n",
    "        if ind[-2:] == 'UA':\n",
    "            methods[ind[:-3]] += list(df[[1,5,9,13,17,21]].loc[ind])\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(methods, orient=\"index\")\n",
    "    print df.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = np.arange(1, 40, 4)\n",
    "IEMOCAP_data_path = '/home/geopar/all_TRUE_IEMOCAP_feats/'\n",
    "iemocap_l_feats_p = os.path.join(IEMOCAP_data_path, 'linear/IEMOCAP_linear_emobase2010')\n",
    "iemocap_nl_feats_p = os.path.join(\n",
    "    IEMOCAP_data_path, \n",
    "    'utterance/IEMOCAP-rqa-ad_hoc-tau-7-supremum-recurrence_rate-0.15-dur-0.03-fs-16000.dat')\n",
    "\n",
    "berlin_data_path = '/home/geopar/all_BERLIN_features/'\n",
    "berlin_l_feats_p = os.path.join(berlin_data_path, 'linear/BERLIN_linear_emobase2010')\n",
    "berlin_nl_feats_p = os.path.join(\n",
    "    berlin_data_path, \n",
    "    'rqa/utterance/BERLIN-rqa-ad_hoc-tau-7-manhattan-recurrence_rate-0.15-dur-0.02-fs-16000.dat')\n",
    "\n",
    "methods_to_test = ['Autoencoder', 'Pattern Search MDS', 'Truncated SVD', 'Spectral Embedding', \n",
    "                   'LLE', 'Modified LLE', 'ISOMAP'] \n",
    "\n",
    "target_dims = [100, 75, 50, 40, 25, 10, 5, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([iemocap_nl_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_sessions = get_iemocap_dataset(data_dic)\n",
    "speaker_groups = iemocap_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-rqa-iemocap.p')\n",
    "iemocap_rqa_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-rqa-iemocap-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(iemocap_rqa_results.keys()):\n",
    "    df = iemocap_rqa_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([iemocap_l_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_sessions = get_iemocap_dataset(data_dic)\n",
    "speaker_groups = iemocap_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-emobase-iemocap.p')\n",
    "iemocap_emobase_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-emobase-iemocap-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(iemocap_emobase_results.keys()):\n",
    "    df = iemocap_emobase_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([iemocap_l_feats_p, iemocap_nl_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_sessions = get_iemocap_dataset(data_dic)\n",
    "speaker_groups = iemocap_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-fused-iemocap.p')\n",
    "iemocap_fused_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-fused-iemocap-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(iemocap_fused_results.keys()):\n",
    "    df = iemocap_fused_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_nl_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_speakers = get_emodb_dataset(data_dic)\n",
    "speaker_groups = emodb_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-rqa-berlin.p')\n",
    "berlin_rqa_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-rqa-berlin-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(berlin_rqa_results.keys()):\n",
    "    df = berlin_rqa_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_l_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_speakers = get_emodb_dataset(data_dic)\n",
    "speaker_groups = emodb_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-emobase-berlin.p')\n",
    "berlin_emobase_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-emobase-berlin-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(berlin_emobase_results.keys()):\n",
    "    df = berlin_emobase_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = IEMOCAP_loader.get_fused_features([berlin_l_feats_p, berlin_nl_feats_p])\n",
    "X_all, y_all, speaker_indices, number_of_speakers = get_emodb_dataset(data_dic)\n",
    "speaker_groups = emodb_speaker_groups(speaker_indices, X_all.shape[0])\n",
    "reduced = run_DR(target_dims, methods_to_test, X_all, saveto='dr-fused-berlin.p')\n",
    "berlin_emobase_results = run_knn_search(reduced, y_all, speaker_groups, saveto='dr-fused-berlin-results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_dim in sorted(berlin_fused_results.keys()):\n",
    "    df = berlin_fused_results[target_dim]\n",
    "    print \"For Target Dimension: {}\".format(target_dim)\n",
    "    print display(df)\n",
    "    latex_preformat_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
